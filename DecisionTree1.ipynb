{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6af7b6-4fa7-48e1-ae58-204f5d26e75d",
   "metadata": {},
   "source": [
    "# __Ques 1__\n",
    "__Desicion tree Algo:__<br>\n",
    "1. Selcet the feature with the highest gain\n",
    "\n",
    "2. Now calculate yes and no in that feature\n",
    "\n",
    "3. make all the classes of it and mark there yes and no's too\n",
    "\n",
    "4. Now calculation precision score. if using entropy or gini and getting 0 than make that node as leaf node\n",
    "\n",
    "5. if precision score is not equal to 0 than split that category futher\n",
    "\n",
    "6. for increasing accuraccy or reducing overfitting using pre or post pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba8606-3786-4fb3-9bda-e14f24c32afd",
   "metadata": {},
   "source": [
    "# __Ques 2__\n",
    "1. calucate the gain for each feature to select the root node\n",
    "\n",
    "2. split the root node into two halves based on some condition\n",
    "\n",
    "3. calcuate the entropy and gini impurity of i they are not zero than split them futhur\n",
    "\n",
    "4. repeat the steps until all last node have entropy or gini Impurity as zero\n",
    "\n",
    "5. When making a prediction for a new object, traverse the decision tree from the root node to a leaf node, following the appropriate branch at each node based on the feature values of the object. The class label associated with the leaf node is the predicted class for the object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439a11e-75e7-4c7f-9d4f-934f0512ecb6",
   "metadata": {},
   "source": [
    "# __Ques 3__\n",
    "\n",
    "- Data preparation: The first step is to prepare the data by splitting it into training and testing sets. The training set is used to train the decision tree model, while the testing set is used to evaluate its performance.\n",
    "\n",
    "- Building the decision tree: The decision tree model is built using the training data set, which consists of labeled data points with known class labels. The decision tree algorithm works by recursively splitting the data based on the values of one or more features. At each split, the algorithm chooses the feature that results in the most information gain, which is a measure of how well the feature splits the data into the two classes.\n",
    "\n",
    "- Testing the model: Once the decision tree model is built, it is tested on the testing data set to evaluate its performance. The model predicts the class label of each test data point based on the path it takes through the decision tree. The predicted class label is then compared to the true class label to calculate the accuracy of the model.\n",
    "\n",
    "- Tuning the model: If the model is not performing well, it may be necessary to tune its parameters or adjust the decision tree structure. For example, the maximum depth of the tree or the minimum number of data points required to split a node could be adjusted to improve performance.\n",
    "\n",
    "- Making predictions: Once the model is trained and tuned, it can be used to make predictions on new, unseen data points. The decision tree algorithm works by recursively splitting the data based on the values of one or more features. At each split, the algorithm chooses the feature that results in the most information gain, which is a measure of how well the feature splits the data into the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3768b7-b7be-4e8a-9f16-0e62f1d1b1de",
   "metadata": {},
   "source": [
    "# __Ques 4__\n",
    "Just traverse the tree and reach at a node verify the condition and your next stop would be its child in such a way that it should be verifying that node's condition now just go on futher and when you reach the leaf node than the class with highest probability is the the class of which that data point belongs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4512d8d-b4db-42fd-8b52-8883ba07b6d7",
   "metadata": {},
   "source": [
    "# __Ques 5__\n",
    "The Confusion matrix is a matrix which is used to summarize the classification model by comparing predicted value by the true value. It is genrally used for binary classification where there is only 2 classes.\n",
    "<br><br>\n",
    "The confusion matrix have 4 values:-\n",
    "- True Positive (TP) represents the number of correctly predicted positive instances.\n",
    "\n",
    "- False Positive (FP) represents the number of incorrectly predicted positive instances.\n",
    "\n",
    "- False Negative (FN) represents the number of incorrectly predicted negative instances.\n",
    "\n",
    "- True Negative (TN) represents the number of correctly predicted negative instances.\n",
    "\n",
    "<br>\n",
    "It is used to evaluate the performance of the classification model as:-\n",
    "- Accuracy score = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "- Precission = TP / (TP + FP)\n",
    "\n",
    "- Recall = TP / (TP + FN)\n",
    "\n",
    "- R1 Score = 2 * (Presission * Recall) / (Presission + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff0ed1-f9a2-4c6b-8b54-9459bb7d499d",
   "metadata": {},
   "source": [
    "# __Ques 6__\n",
    "Let consutsion Matrix be :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa00e217-ff46-4993-89e9-d497900d71a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 20], [10, 200]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix=[[100 , 20],[10 , 200]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760e53a5-44fa-4ce3-8433-097a709ca02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=matrix[0][0]\n",
    "TN=matrix[1][1]\n",
    "FP=matrix[0][1]\n",
    "FN=matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e8903c-d331-4ed8-877e-7e0c258c7209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score is : 0.9090909090909091\n",
      "The precision score is : 0.8333333333333334\n",
      "The recall score is : 0.9090909090909091\n",
      "The R1 Score is : 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(\"The Accuracy score is :\",accuracy)\n",
    "\n",
    "precision=TP/(TP+FP)\n",
    "print(\"The precision score is :\",precision)\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "print(\"The recall score is :\",recall)\n",
    "\n",
    "r1_score=2*(precision*recall)/(precision+recall)\n",
    "print(\"The R1 Score is :\",r1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21629a0-ce80-4c97-8e80-17b6e8375f09",
   "metadata": {},
   "source": [
    "# __Ques 7__\n",
    "Choosing an appropriate evaluation metric for a classification problem is crucial because different metrics measure different aspects of model performance and may be more or less important depending on the application. For example, in a medical diagnosis task, where the cost of missing a positive case (false negative) is high, recall may be a more important metric than precision. On the other hand, in a fraud detection task, where the cost of false positives is high, precision may be more important than recall.\n",
    "<br>\n",
    "To choose an appropriate evaluation metric, it is important to consider the nature of the problem, the consequences of false positives and false negatives, and the overall goals of the application. It is also important to evaluate the model's performance using multiple metrics and to consider the trade-offs between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148676cb-d20a-4fc6-8694-bb06c84a9cd4",
   "metadata": {},
   "source": [
    "# __Ques 8__\n",
    "An example of a classification problem where precision is the most important metric is spam email classification. In this task, the goal is to identify whether an email is spam or not. False positives (classifying a non-spam email as spam) can be annoying for the recipient, but false negatives (classifying a spam email as non-spam) can be dangerous because it can lead to the recipient being scammed or hacked. Therefore, in this task, precision is a more important metric than recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566b2eb-6b51-4f75-84a0-6f2c3334b430",
   "metadata": {},
   "source": [
    "# __Ques 9__\n",
    "An example of a classification problem where recall is the most important metric is cancer diagnosis. In this task, the goal is to identify whether a patient has cancer or not. False negatives (classifying a patient with cancer as cancer-free) can have life-threatening consequences, while false positives (classifying a cancer-free patient as having cancer) can lead to unnecessary and costly medical procedures. Therefore, in this task, recall is a more important metric than precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
